{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, StratifiedShuffleSplit \n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().magic('matplotlib inline')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Reading the file\n",
    "def read_file(trainF,testF, Directory, Target_col,transform,drop_cols=None,categ_transform=None):\n",
    "    train = pd.read_csv(Directory + trainF)\n",
    "    test =  pd.read_csv(Directory + testF)\n",
    "    if transform:\n",
    "        lbl_enc = preprocessing.LabelEncoder()\n",
    "        labels = train[Target_col].values\n",
    "        labels = lbl_enc.fit_transform(labels)\n",
    "        labels_test = test[Target_col].values\n",
    "        labels_test = lbl_enc.fit_transform(labels_test)\n",
    "        train.drop([Target_col],axis=1)\n",
    "        test.drop([Target_col],axis=1)\n",
    "        train[Target_col] = labels\n",
    "        test[Target_col] = labels_test\n",
    "    if drop_cols is not None:\n",
    "        for i in drop_cols:\n",
    "            train.drop([i],axis=1,inplace=True)\n",
    "            test.drop([i],axis=1,inplace=True)\n",
    "    if categ_transform is not None:\n",
    "        for j in categ_transform:\n",
    "            lbl_enc = preprocessing.LabelEncoder()\n",
    "            labels = train[j].values\n",
    "            labels = lbl_enc.fit_transform(labels)\n",
    "            labels_test = test[j].values\n",
    "            labels_test = lbl_enc.fit_transform(labels_test)\n",
    "            train.drop([j],axis=1)\n",
    "            test.drop([j],axis=1)\n",
    "            train[j] = labels\n",
    "            test[j] = labels_test\n",
    "            \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## SVM classifier\n",
    "def svm_classifier(train, test, accuracy, roc_auc, Target_col):\n",
    "    y = train[Target_col]\n",
    "    X = train.drop([Target_col],axis=1)\n",
    "    test_labels = test[Target_col]\n",
    "    test_X = test.drop([Target_col],axis=1)\n",
    "    random_state = np.random.RandomState(0)\n",
    "    # Binarize the output\n",
    "    y = label_binarize(y, classes=np.unique(y))\n",
    "    test_labels = label_binarize(test_labels, classes=np.unique(test_labels))\n",
    "    n_classes = y.shape[1]\n",
    "    classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=random_state))\n",
    "    y_score = classifier.fit(X, y).decision_function(test_X)\n",
    "    y_pred = classifier.predict(test_X)\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(test_labels[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_labels.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    accuracy.append(metrics.accuracy_score(test_labels, y_pred))\n",
    "    return accuracy, roc_auc[\"micro\"]\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    clf = svm.SVC(probability=True)\n",
    "    clf.fit(X,y)\n",
    "    y_pred = clf.predict(test_X)\n",
    "    accuracy.append(metrics.accuracy_score(test_labels, y_pred))\n",
    "    probas_ = clf.predict_proba(test_X)\n",
    "    # Compute ROC curve and area the curve\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(test_labels, probas_[:, 1])\n",
    "    roc_auc.append(auc(false_positive_rate, true_positive_rate))\n",
    "    return accuracy, roc_auc\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## RF classifier\n",
    "def RF_classifier(train, test, accuracy, roc_auc, Target_col):\n",
    "    y = train[Target_col]\n",
    "    X = train.drop([Target_col],axis=1)\n",
    "    test_labels = test[Target_col]\n",
    "    test_X = test.drop([Target_col],axis=1)\n",
    "    \n",
    "    ##Binarize the output\n",
    "    y = label_binarize(y, classes=np.unique(y))\n",
    "    test_labels = label_binarize(test_labels, classes=np.unique(test_labels))\n",
    "    n_classes = y.shape[1]\n",
    "    #RF = OneVsRestClassifier(RandomForestClassifier(n_estimators = 200, random_state = 100, \n",
    "    #                class_weight = 'balanced', oob_score = True))\n",
    "    RF = RandomForestClassifier(n_estimators = 200, random_state = 0, \n",
    "                oob_score = True)\n",
    "    RF.fit(X,y)\n",
    "    y_pred = RF.predict(test_X)\n",
    "    accuracy.append(metrics.accuracy_score(test_labels, y_pred))\n",
    "    return accuracy, roc_auc\n",
    "    #y_score = RF.predict_proba(test_X)\n",
    "    \"\"\"\n",
    "    probas_ = RF.predict_proba(test_X)\n",
    "    \n",
    "    # Compute ROC curve and area the curve\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(test_labels, probas_)[:, 1]\n",
    "    roc_auc.append(auc(false_positive_rate, true_positive_rate))\n",
    "    return accuracy, roc_auc\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Logistic Regression\n",
    "def log_classifier(train, test, accuracy, roc_auc, Target_col):\n",
    "    y = train[Target_col]\n",
    "    X = train.drop([Target_col],axis=1)\n",
    "    test_labels = test[Target_col]\n",
    "    test_X = test.drop([Target_col],axis=1)\n",
    "    logreg = linear_model.LogisticRegression()\n",
    "    logreg.fit(X,y)\n",
    "    y_pred = logreg.predict(test_X)\n",
    "    accuracy.append(metrics.accuracy_score(test_labels, y_pred))\n",
    "    \"\"\"\n",
    "    probas_ = logreg.predict_proba(test_X)\n",
    "    # Compute ROC curve and area the curve\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(test_labels, probas_[:, 1])\n",
    "    roc_auc.append(auc(false_positive_rate, true_positive_rate))\n",
    "    \"\"\"\n",
    "    return accuracy, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Decision Tree\n",
    "def tree_classifier(train, test, accuracy, roc_auc, Target_col):\n",
    "    y = train[Target_col]\n",
    "    X = train.drop([Target_col],axis=1)\n",
    "    test_labels = test[Target_col]\n",
    "    test_X = test.drop([Target_col],axis=1)\n",
    "    tree = DecisionTreeClassifier(random_state=0)\n",
    "    tree.fit(X,y)\n",
    "    y_pred = tree.predict(test_X)\n",
    "    accuracy.append(metrics.accuracy_score(test_labels, y_pred))\n",
    "    \"\"\"\n",
    "    probas_ = tree.predict_proba(test_X)\n",
    "    # Compute ROC curve and area the curve\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(test_labels, probas_)[:, 1]\n",
    "    roc_auc.append(auc(false_positive_rate, true_positive_rate))\n",
    "    \"\"\"\n",
    "    return accuracy, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_build(filenum,Target_column, df_train, df_test, Directory,drop_cols=None,categ_transform=None):\n",
    "    accuracy_svm = []; roc_auc_svm = []\n",
    "    accuracy_RF = []; roc_auc_RF = []\n",
    "    accuracy_log = []; roc_auc_log = []\n",
    "    accuracy_tree = []; roc_auc_tree = []\n",
    "    Target_col = Target_column\n",
    "    for i in range(1,11):\n",
    "        trainF = df_train+ str(i) + '.csv'\n",
    "        testF = df_test + str(i) + '.csv'\n",
    "        train, test = read_file(trainF,testF,Directory, Target_col,transform=True,drop_cols=drop_cols,categ_transform=categ_transform)\n",
    "        accuracy_svm, roc_auc_svm = svm_classifier(train, test, accuracy_svm, roc_auc_svm, Target_col)\n",
    "        accuracy_RF, roc_auc_RF = RF_classifier(train, test, accuracy_RF, roc_auc_RF, Target_col)\n",
    "        accuracy_log, roc_auc_log = log_classifier(train, test, accuracy_log, roc_auc_log, Target_col)\n",
    "        accuracy_tree, roc_auc_tree = tree_classifier(train, test, accuracy_tree, roc_auc_tree, Target_col)\n",
    "    print('Data set# ' + str(filenum))\n",
    "    print('********** SVM classifier ***********')\n",
    "    print('Accuracy mean   ' + 'Accuracy Stdev  ')\n",
    "    print(np.array(accuracy_svm).mean(), np.array(accuracy_svm).std())\n",
    "    print('AUC mean        ' + 'AUC      Stdev  ')\n",
    "    print(np.array(roc_auc_svm).mean(), np.array(roc_auc_svm).std())\n",
    "    print()\n",
    "\n",
    "    print('********** RF classifier ************')\n",
    "    print('Accuracy mean   ' + 'Accuracy Stdev  ')\n",
    "    print(np.array(accuracy_RF).mean(), np.array(accuracy_RF).std())\n",
    "    print('AUC mean        ' + 'AUC      Stdev  ')\n",
    "    print(np.array(roc_auc_RF).mean(), np.array(roc_auc_RF).std())\n",
    "    print()\n",
    "    print('********** Logistic regression ******')\n",
    "    print('Accuracy mean   ' + 'Accuracy Stdev  ')\n",
    "    print(np.array(accuracy_log).mean(), np.array(accuracy_log).std())\n",
    "    print('AUC mean        ' + 'AUC      Stdev  ')\n",
    "    print(np.array(roc_auc_log).mean(), np.array(roc_auc_log).std())\n",
    "    print()\n",
    "    print('****** Decision Tree classifier *****')\n",
    "    print('Accuracy mean   ' + 'Accuracy Stdev  ')\n",
    "    print(np.array(accuracy_tree).mean(), np.array(accuracy_tree).std())\n",
    "    print('AUC mean        ' + 'AUC      Stdev  ')\n",
    "    print(np.array(roc_auc_tree).mean(), np.array(roc_auc_tree).std())\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    2.4s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    9.4s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    9.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    8.4s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    8.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    2.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    9.0s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    1.8s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    7.8s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    7.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    9.1s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    9.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    1.8s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    7.4s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    7.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    2.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    9.2s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    9.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    1.9s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    7.7s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    7.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    2.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    8.6s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    8.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    8.1s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    8.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    2.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    9.1s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    9.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    1.9s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    7.7s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    7.8s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    2.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    9.0s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    9.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    1.8s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    7.6s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    7.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    2.4s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:   10.4s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:   10.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    2.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    7.7s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    7.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    2.2s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    9.1s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    9.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    1.8s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    7.6s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    7.7s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    2.1s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    9.1s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    9.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    7.3s\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    7.4s finished\n",
      "//anaconda/lib/python3.5/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set# 2\n",
      "********** SVM classifier ***********\n",
      "Accuracy mean   Accuracy Stdev  \n",
      "0.353667709088 0.00684817781504\n",
      "AUC mean        AUC      Stdev  \n",
      "0.906650486049 0.0\n",
      "\n",
      "********** RF classifier ************\n",
      "Accuracy mean   Accuracy Stdev  \n",
      "0.78412086085 0.00314022025978\n",
      "AUC mean        AUC      Stdev  \n",
      "nan nan\n",
      "\n",
      "********** Logistic regression ******\n",
      "Accuracy mean   Accuracy Stdev  \n",
      "0.710795087387 0.00482357695207\n",
      "AUC mean        AUC      Stdev  \n",
      "nan nan\n",
      "\n",
      "****** Decision Tree classifier *****\n",
      "Accuracy mean   Accuracy Stdev  \n",
      "0.820478288835 0.00518612409593\n",
      "AUC mean        AUC      Stdev  \n",
      "nan nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/numpy/core/_methods.py:82: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "model_build(filenum=2,Target_column='letter', df_train='data2_train', df_test='data2_test', Directory = \"./Data Set 2/splits/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_build(filenum=4,Target_column='Activity', df_train='data4_train', df_test='data4_test', Directory = \"./Data Set 4/splits/\",drop_cols=['Tag_Identificator'],categ_transform=['Sequence_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_build(filenum=6,Target_column='Class', df_train='d6_train', df_test='d6_test', Directory = \"./Data Set 6/splits/\",drop_cols=None,categ_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_build(filenum=7,Target_column='Class', df_train='d7_train', df_test='d7_test', Directory = \"./Data Set 7/splits/\",drop_cols=None,categ_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_build(filenum=12,Target_column='C118', df_train='brain_train', df_test='brain_test', Directory = \"./data12_brain/\",drop_cols=None,categ_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_build(filenum=14,Target_column='C2309', df_train='srbct_train', df_test='srbct_test', Directory = \"./data14_srbct/\",drop_cols=None,categ_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_build(filenum=15,Target_column='C94', df_train='lymph_train', df_test='lymph_test', Directory = \"./data15_lymph/\",drop_cols=None,categ_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
